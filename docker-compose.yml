version: "3.9"

services:
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: webda-backend
    ports:
      - "8000:8000"
    environment:
      # для LLM
      - OLLAMA_HOST=http://ollama:11434
      - OLLAMA_MODEL=llama3
      # соль для паролей
      - AUTH_SALT=super_secret_salt_change_me
    volumes:
      # чтобы users.json и аватары не терялись между рестартами
      - ./backend/data/users.json:/app/app/users.json
      - ./backend/data/user_uploads:/app/app/user_uploads

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: webda-frontend
    ports:
      - "80:80"
    depends_on:
      - backend
    environment:
      # Внутри Docker нам НЕ нужен внешний URL,
      # api.js использует "/api" и nginx сам проксирует.
      - VITE_API_BASE_URL=/api

  # опциональный сервис для ollama, если нужен прямо в Docker
  # ollama:
  #   image: ollama/ollama
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama_data:/root/.ollama

#volumes:
#  ollama_data:
